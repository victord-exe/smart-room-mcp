# Arquitectura del Sistema
## Smart Room Control System (SRCS)

**Universidad Tecnol√≥gica de Panam√°**
**Facultad de Ingenier√≠a de Sistemas Computacionales**

**Autores:** Alejandro Mosquera, Victor Rodr√≠guez
**Versi√≥n:** 1.0
**Fecha:** Enero 2025

---

## Tabla de Contenido

1. [Introducci√≥n](#1-introducci√≥n)
2. [Diagrama de Contexto (C4 Level 1)](#2-diagrama-de-contexto-c4-level-1)
3. [Diagrama de Contenedores (C4 Level 2)](#3-diagrama-de-contenedores-c4-level-2)
4. [Diagrama de Componentes (C4 Level 3)](#4-diagrama-de-componentes-c4-level-3)
5. [Diagrama de Despliegue](#5-diagrama-de-despliegue)
6. [Patrones Arquitect√≥nicos](#6-patrones-arquitect√≥nicos)
7. [Decisiones Arquitect√≥nicas (ADRs)](#7-decisiones-arquitect√≥nicas-adrs)
8. [Flujo de Datos](#8-flujo-de-datos)

---

## 1. Introducci√≥n

Este documento describe la arquitectura de software del Smart Room Control System (SRCS), siguiendo el modelo C4 (Context, Containers, Components, Code) para proporcionar vistas en diferentes niveles de abstracci√≥n.

### 1.1 Objetivos Arquitect√≥nicos

1. **Modularidad**: Componentes independientes y reemplazables
2. **Escalabilidad**: Soporte para agregar dispositivos y subsistemas sin redise√±o
3. **Privacidad**: Procesamiento local sin dependencias externas
4. **Interoperabilidad**: Uso de MCP como protocolo est√°ndar
5. **Mantenibilidad**: C√≥digo organizado, documentado y testeable

### 1.2 Principios de Dise√±o

- **Separation of Concerns**: Cada componente tiene responsabilidad √∫nica y bien definida
- **Dependency Inversion**: Componentes de alto nivel no dependen de detalles de implementaci√≥n
- **Open/Closed Principle**: Abierto para extensi√≥n, cerrado para modificaci√≥n
- **Single Source of Truth**: Configuraci√≥n centralizada
- **Fail Fast**: Detecci√≥n temprana de errores con logging comprehensivo

### 1.3 Base Tecnol√≥gica: mcp-client-cli

**DECISI√ìN ARQUITECT√ìNICA CLAVE** (ver [00-ADR-Base-Tecnologica.md](./00-ADR-Base-Tecnologica.md#adr-001-uso-de-mcp-client-cli-como-base-del-proyecto))

El Smart Room Control System se construye sobre [**mcp-client-cli**](https://github.com/adhikasp/mcp-client-cli), un cliente CLI open-source para Model Context Protocol. Esta decisi√≥n proporciona:

**Componentes Base Ya Implementados (~40% del sistema):**

| Componente | Archivo en mcp-client | Requisitos Cubiertos | Estado |
|------------|----------------------|---------------------|--------|
| **Cliente Coordinador MCP** | `tool.py` (McpToolkit) | RF-007, RF-008, RF-011 | ‚úÖ Reutilizar |
| **Agente LLM** | `cli.py` + LangGraph | RF-001, RF-002, RF-004, RF-006 | ‚úÖ Reutilizar |
| **Sistema de Configuraci√≥n** | `config.py` | RF-028 (parcial) | ‚úèÔ∏è Extender para IoT |
| **Memoria Persistente** | `memory.py` (SqliteStore) | RF-032 | ‚úèÔ∏è Extender |
| **Cache de Herramientas** | `storage.py` | RF-011 | ‚úÖ Reutilizar |
| **Interfaz STT** | `whisperVoiceInterface.py` | RF-019 | ‚úÖ Reutilizar |
| **Interfaz CLI** | `cli.py`, `input.py`, `output.py` | RF-020, RF-022 | ‚úèÔ∏è Extender |
| **Historial Conversacional** | AsyncSqliteSaver (LangGraph) | RF-032 | ‚úÖ Reutilizar |

**Componentes Nuevos a Desarrollar (~60% del sistema):**

| Componente | Ubicaci√≥n Propuesta | Requisitos | Estimaci√≥n |
|------------|-------------------|------------|-----------|
| **Servidores MCP IoT** | `src/mcp-servers/` | RF-012 a RF-015 | 40h |
| **Conectores IoT** | `src/iot-connectors/` | RF-016 a RF-018 | 30h |
| **Gesti√≥n de Escenas** | `src/scenes/` | RF-024 a RF-026 | 15h |
| **TTS (Text-to-Speech)** | `src/ui/tts_interface.py` | RF-021 | 8h |
| **Administraci√≥n** | `src/admin/` | RF-027, RF-029, RF-030 | 10h |
| **Aprendizaje de Preferencias** | `src/learning/` | RF-031, RF-033 | 7h |

**Beneficios de esta Arquitectura:**
- ‚ö° **Ahorro de ~90 horas** de desarrollo (37.5%)
- ‚úÖ **C√≥digo probado** en producci√≥n con tests de integraci√≥n
- üèóÔ∏è **Fundaci√≥n s√≥lida** para extensi√≥n con servidores MCP IoT
- üîÑ **Compatibilidad** con especificaci√≥n MCP oficial
- üìö **Documentaci√≥n existente** (README.md, CLAUDE.md, CONFIG.md)

**Estrategia de Integraci√≥n:**
1. **Fork** del repositorio mcp-client-cli
2. **Renombrar** proyecto a smart-room-mcp
3. **Extender** base de datos con tablas para dispositivos, escenas, m√©tricas
4. **Crear** servidores MCP especializados para IoT
5. **Mantener** cr√©ditos y licencia MIT del proyecto original

---

## 2. Diagrama de Contexto (C4 Level 1)

El diagrama de contexto muestra el sistema en su entorno, interactuando con usuarios y sistemas externos.

```plantuml
@startuml C4_Context
!include https://raw.githubusercontent.com/plantuml-stdlib/C4-PlantUML/master/C4_Context.puml

title Smart Room Control System - Context Diagram

Person(user, "Usuario del Smart Room", "Persona que habita o usa el Smart Room")
Person(admin, "Administrador", "Responsable de configurar y mantener el sistema")
Person(developer, "Desarrollador", "Extiende funcionalidad del sistema")

System(srcs, "Smart Room Control System", "Sistema inteligente para control unificado de dispositivos IoT mediante agentes AI y MCP")

System_Ext(devices_lighting, "Dispositivos de Iluminaci√≥n", "Philips Hue, LIFX")
System_Ext(devices_climate, "Dispositivos de Climatizaci√≥n", "Nest, Ecobee")
System_Ext(devices_security, "Dispositivos de Seguridad", "C√°maras IP, sensores")
System_Ext(devices_entertainment, "Dispositivos de Entretenimiento", "Sonos, Chromecast")

Rel(user, srcs, "Controla ambiente mediante voz/texto", "Comandos en lenguaje natural")
Rel(admin, srcs, "Configura y monitorea", "Interfaz web/CLI")
Rel(developer, srcs, "Extiende funcionalidad", "APIs, Servidores MCP personalizados")

Rel(srcs, devices_lighting, "Controla iluminaci√≥n", "API REST")
Rel(srcs, devices_climate, "Controla temperatura", "API REST")
Rel(srcs, devices_security, "Gestiona seguridad", "ONVIF, API REST")
Rel(srcs, devices_entertainment, "Controla audio/video", "API REST")

@enduml
```

### 2.1 Actores Externos

**Usuario Final**
- Interact√∫a mediante voz o texto en lenguaje natural
- Objetivo: Controlar ambiente de forma intuitiva
- Ejemplos: Estudiante en laboratorio Smart Room, profesor dando clase

**Administrador del Sistema**
- Gestiona configuraci√≥n y dispositivos
- Monitorea logs y m√©tricas de rendimiento
- Objetivo: Mantener sistema operativo y optimizado

**Desarrollador/Investigador**
- Crea nuevos servidores MCP personalizados
- Integra nuevos dispositivos IoT
- Objetivo: Extender capacidades del sistema

**Sistemas Externos (Dispositivos IoT)**
- Ejecutan acciones f√≠sicas (encender luces, ajustar temperatura, etc.)
- Reportan estado actual al sistema
- Comunicaci√≥n mediante APIs REST, MQTT, Zigbee, etc.

---

## 3. Diagrama de Contenedores (C4 Level 2)

Los contenedores representan aplicaciones o servicios ejecutables del sistema.

```plantuml
@startuml C4_Container
!include https://raw.githubusercontent.com/plantuml-stdlib/C4-PlantUML/master/C4_Container.puml

title Smart Room Control System - Container Diagram

Person(user, "Usuario", "Usuario del Smart Room")

System_Boundary(srcs, "Smart Room Control System") {
    Container(ui, "User Interface", "Python, Rich CLI / FastAPI Web", "Interfaz de voz y texto para interacci√≥n con el usuario")

    Container(llm_agent, "LLM Agent", "Python, LangChain, Ollama", "Cerebro del sistema: Procesa lenguaje natural, toma decisiones, orquesta acciones")

    Container(mcp_coordinator, "MCP Coordinator", "Python, MCP SDK", "Gestiona conexiones con servidores MCP, invoca herramientas, consolida respuestas")

    Container(mcp_server_lighting, "MCP Lighting Server", "Python, MCP SDK", "Expone herramientas para control de iluminaci√≥n")

    Container(mcp_server_climate, "MCP Climate Server", "Python, MCP SDK", "Expone herramientas para climatizaci√≥n")

    Container(mcp_server_security, "MCP Security Server", "Python, MCP SDK", "Expone herramientas para seguridad")

    Container(mcp_server_entertainment, "MCP Entertainment Server", "Python, MCP SDK", "Expone herramientas para audio/video")

    Container(iot_connectors, "IoT Connectors", "Python, API Clients", "Adaptadores que traducen comandos MCP a APIs de dispositivos espec√≠ficos")

    ContainerDb(database, "Database", "SQLite", "Almacena preferencias, historial, configuraci√≥n, escenas")

    ContainerDb(config, "Configuration Files", "JSON", "Configuraci√≥n de servidores MCP, dispositivos, sistema")
}

System_Ext(devices, "Dispositivos IoT", "Philips Hue, Nest, C√°maras, Sonos")
System_Ext(llm_model, "Llama Model", "Modelo LLM ejecutado por Ollama")

Rel(user, ui, "Comandos de voz/texto", "HTTP/WebSocket/CLI")
Rel(ui, llm_agent, "Env√≠a transcripci√≥n/texto", "Python function call")
Rel(llm_agent, llm_model, "Solicita inferencia", "HTTP API")
Rel(llm_agent, mcp_coordinator, "Orquesta acciones", "Python function call")
Rel(llm_agent, database, "Consulta contexto, preferencias", "SQLAlchemy")

Rel(mcp_coordinator, mcp_server_lighting, "Invoca herramientas", "JSON-RPC over stdio")
Rel(mcp_coordinator, mcp_server_climate, "Invoca herramientas", "JSON-RPC over stdio")
Rel(mcp_coordinator, mcp_server_security, "Invoca herramientas", "JSON-RPC over stdio")
Rel(mcp_coordinator, mcp_server_entertainment, "Invoca herramientas", "JSON-RPC over stdio")

Rel(mcp_server_lighting, iot_connectors, "Delega ejecuci√≥n", "Python function call")
Rel(mcp_server_climate, iot_connectors, "Delega ejecuci√≥n", "Python function call")
Rel(mcp_server_security, iot_connectors, "Delega ejecuci√≥n", "Python function call")
Rel(mcp_server_entertainment, iot_connectors, "Delega ejecuci√≥n", "Python function call")

Rel(iot_connectors, devices, "Controla dispositivos", "API REST/MQTT/Zigbee")

Rel(mcp_coordinator, config, "Lee configuraci√≥n de servidores", "File I/O")
Rel(llm_agent, config, "Lee system prompt, configuraci√≥n LLM", "File I/O")

@enduml
```

### 3.1 Descripci√≥n de Contenedores

#### User Interface (UI)
- **Tecnolog√≠a**: Python, Rich (CLI), FastAPI (web opcional)
- **Responsabilidades**:
  - Captura de entrada de voz mediante micr√≥fono
  - Conversi√≥n Speech-to-Text con Whisper
  - Aceptaci√≥n de entrada de texto
  - Conversi√≥n Text-to-Speech con Bark/Piper
  - Display de respuestas
- **Interfaz**: CLI principal, API HTTP/WebSocket opcional

#### LLM Agent
- **Tecnolog√≠a**: Python, LangChain, LangGraph, Ollama client
- **Responsabilidades**:
  - Procesamiento de lenguaje natural
  - Toma de decisiones contextuales
  - Planificaci√≥n de acciones complejas
  - Gesti√≥n de conversaci√≥n multi-turno
  - Aprendizaje de preferencias
- **Modelo**: Llama 3.1 8B o superior (ejecutado por Ollama)

#### MCP Coordinator
- **Tecnolog√≠a**: Python, MCP SDK oficial
- **Responsabilidades**:
  - Descubrimiento y conexi√≥n con servidores MCP
  - Gesti√≥n de pool de conexiones (stdio)
  - Invocaci√≥n de herramientas seg√∫n indicaciones del LLM
  - Consolidaci√≥n de respuestas
  - Cach√© de capacidades de servidores
- **Protocolo**: JSON-RPC 2.0 sobre stdio

#### MCP Servers (Lighting, Climate, Security, Entertainment)
- **Tecnolog√≠a**: Python, MCP SDK oficial
- **Responsabilidades**:
  - Exposici√≥n de herramientas espec√≠ficas del dominio
  - Validaci√≥n de par√°metros
  - Delegaci√≥n a conectores IoT
  - Retorno de resultados estandarizados
- **Protocolo**: JSON-RPC 2.0 sobre stdio

#### IoT Connectors
- **Tecnolog√≠a**: Python, librer√≠as de clientes (phue, python-nest, soco, etc.)
- **Responsabilidades**:
  - Traducci√≥n de comandos MCP a APIs nativas de dispositivos
  - Autenticaci√≥n y manejo de sesiones
  - Manejo de errores espec√≠ficos de dispositivos
  - Normalizaci√≥n de respuestas
- **Patr√≥n**: Adapter Pattern

#### Database (SQLite)
- **Tecnolog√≠a**: SQLite 3, SQLAlchemy ORM
- **Responsabilidades**:
  - Persistencia de preferencias de usuario
  - Historial de conversaciones (LangGraph checkpoints)
  - Almacenamiento de escenas y rutinas
  - Logs de acciones ejecutadas
  - M√©tricas de rendimiento
- **Ubicaci√≥n**: `~/.llm/conversations.db`

#### Configuration Files
- **Formato**: JSON con soporte de comentarios (commentjson)
- **Archivos**:
  - `config.json`: Configuraci√≥n general, system prompt, configuraci√≥n LLM
  - `mcp-servers-config.json`: Configuraci√≥n de servidores MCP
  - `devices-config.json`: Registro de dispositivos IoT
- **Ubicaci√≥n**: `~/.llm/` o `./config/`

---

## 4. Diagrama de Componentes (C4 Level 3)

Detalle de componentes internos del contenedor **LLM Agent**.

```plantuml
@startuml C4_Component_LLM_Agent
!include https://raw.githubusercontent.com/plantuml-stdlib/C4-PlantUML/master/C4_Component.puml

title Smart Room Control System - LLM Agent Components

Container(ui, "User Interface", "Python")
Container(mcp_coordinator, "MCP Coordinator", "Python")
ContainerDb(database, "Database", "SQLite")
System_Ext(ollama, "Ollama Service", "LLM Runtime")

Container_Boundary(llm_agent, "LLM Agent") {
    Component(nlp_processor, "NLP Processor", "Python, LangChain", "Interpreta comandos en lenguaje natural, extrae intenci√≥n y entidades")

    Component(decision_engine, "Decision Engine", "Python, LangChain", "Toma decisiones basadas en contexto y preferencias")

    Component(action_planner, "Action Planner", "Python, LangGraph", "Descompone tareas complejas en acciones at√≥micas, determina orden de ejecuci√≥n")

    Component(context_manager, "Context Manager", "Python", "Gestiona contexto de conversaci√≥n, recupera informaci√≥n relevante de DB")

    Component(preference_learner, "Preference Learner", "Python", "Analiza patrones de uso, aprende preferencias del usuario")

    Component(response_generator, "Response Generator", "Python, LangChain", "Genera respuestas en lenguaje natural basadas en resultados de acciones")

    Component(llm_interface, "LLM Interface", "Python, Ollama client", "Abstracci√≥n para comunicaci√≥n con Ollama/Llama")
}

Rel(ui, nlp_processor, "Env√≠a texto de comando", "Python call")
Rel(nlp_processor, llm_interface, "Solicita inferencia", "HTTP")
Rel(llm_interface, ollama, "Genera respuesta", "HTTP API")

Rel(nlp_processor, context_manager, "Solicita contexto", "Python call")
Rel(context_manager, database, "Consulta historial, preferencias", "SQLAlchemy")

Rel(nlp_processor, decision_engine, "Pasa intenci√≥n y entidades", "Python call")
Rel(decision_engine, action_planner, "Solicita plan de acci√≥n", "Python call")
Rel(decision_engine, preference_learner, "Consulta preferencias", "Python call")

Rel(action_planner, mcp_coordinator, "Invoca herramientas MCP", "Python call")
Rel(mcp_coordinator, action_planner, "Retorna resultados", "Python call")

Rel(action_planner, response_generator, "Solicita generaci√≥n de respuesta", "Python call")
Rel(response_generator, llm_interface, "Solicita generaci√≥n de texto", "HTTP")
Rel(response_generator, ui, "Env√≠a respuesta", "Python call")

Rel(preference_learner, database, "Almacena preferencias aprendidas", "SQLAlchemy")

@enduml
```

### 4.1 Componentes del LLM Agent

**NLP Processor**
- Entrada: Texto del comando (transcripci√≥n de voz o texto directo)
- Procesamiento: An√°lisis sint√°ctico, extracci√≥n de intenci√≥n y entidades mediante LLM
- Salida: Estructura `Intent(action, entities, parameters)`
- Tecnolog√≠a: LangChain PromptTemplate + Llama

**Decision Engine**
- Entrada: Intenci√≥n + contexto + preferencias
- Procesamiento: Aplicaci√≥n de reglas de negocio, consideraci√≥n de estado actual
- Salida: Decisi√≥n de acci√≥n a ejecutar
- Patr√≥n: Rule Engine + Context-aware AI

**Action Planner**
- Entrada: Decisi√≥n de alto nivel (ej: "activar modo cine")
- Procesamiento: Descomposici√≥n en acciones at√≥micas, determinaci√≥n de secuencialidad/paralelismo
- Salida: Grafo de acciones con dependencias
- Tecnolog√≠a: LangGraph (agent with state)

**Context Manager**
- Entrada: Solicitudes de contexto (estado actual, historial, etc.)
- Procesamiento: Recuperaci√≥n de DB, construcci√≥n de contexto relevante
- Salida: Diccionario de contexto
- Optimizaci√≥n: Cach√© en memoria para contexto frecuente

**Preference Learner**
- Entrada: Historial de acciones del usuario
- Procesamiento: Detecci√≥n de patrones, inferencia de preferencias
- Salida: Reglas de preferencia almacenadas
- Algoritmo: An√°lisis de frecuencia + clustering temporal

**Response Generator**
- Entrada: Resultado de acciones ejecutadas
- Procesamiento: Generaci√≥n de texto natural explicando resultado
- Salida: Texto de respuesta
- Tecnolog√≠a: LangChain + Llama con template de respuestas

**LLM Interface**
- Entrada: Prompt formateado para Llama
- Procesamiento: Comunicaci√≥n con Ollama, manejo de streaming
- Salida: Texto generado o estructura JSON
- Abstracci√≥n: Permite intercambiar backend LLM

---

## 5. Diagrama de Despliegue

```plantuml
@startuml Deployment
!include https://raw.githubusercontent.com/plantuml-stdlib/C4-PlantUML/master/C4_Deployment.puml

title Smart Room Control System - Deployment Diagram

Deployment_Node(smartroom, "Smart Room Environment", "Physical Lab") {

    Deployment_Node(server, "Server Principal", "Ubuntu 22.04 LTS / Windows 11") {
        Deployment_Node(python_env, "Python Virtual Environment", "Python 3.12+") {
            Container(srcs_app, "SRCS Application", "Python processes", "LLM Agent, MCP Coordinator, Servers MCP, UI")
        }

        Deployment_Node(ollama_service, "Ollama Service", "Systemd service / Windows Service") {
            Container(llm_model, "Llama 3.1 8B", "GGUF format", "Modelo LLM cargado en VRAM")
        }

        Deployment_Node(storage, "Storage", "SSD NVMe") {
            ContainerDb(sqlite_db, "SQLite Database", "conversations.db", "Preferencias, historial, configuraci√≥n")
            ContainerDb(config_files, "Config Files", "JSON", "Configuraci√≥n del sistema")
        }
    }

    Deployment_Node(network, "Local Network", "Gigabit Ethernet / WiFi 6") {
        Deployment_Node(hue_bridge, "Philips Hue Bridge", "IoT Hub") {
            System_Ext(hue_lights, "Philips Hue Lights", "Bombillas inteligentes")
        }

        System_Ext(nest_thermostat, "Nest Thermostat", "Termostato inteligente")
        System_Ext(ip_camera, "IP Camera", "C√°mara de seguridad")
        System_Ext(sonos_speaker, "Sonos Speaker", "Altavoz inteligente")
    }

    Deployment_Node(user_devices, "User Devices", "Optional") {
        System_Ext(web_browser, "Web Browser", "Interfaz web de administraci√≥n")
    }
}

Rel(srcs_app, llm_model, "Solicita inferencia", "HTTP localhost:11434")
Rel(srcs_app, sqlite_db, "Lee/Escribe datos", "File I/O")
Rel(srcs_app, config_files, "Lee configuraci√≥n", "File I/O")

Rel(srcs_app, hue_bridge, "Controla luces", "HTTP API REST")
Rel(srcs_app, nest_thermostat, "Controla clima", "HTTP API REST")
Rel(srcs_app, ip_camera, "Obtiene stream", "RTSP/ONVIF")
Rel(srcs_app, sonos_speaker, "Controla audio", "HTTP API REST")

Rel(web_browser, srcs_app, "Accede a interfaz web", "HTTPS (opcional)")

@enduml
```

### 5.1 Descripci√≥n del Despliegue

**Servidor Principal**
- **Hardware**: Seg√∫n especificaciones RH-001 a RH-006 (ver SRS)
- **SO**: Ubuntu 22.04 LTS (preferido) o Windows 11 Pro
- **Servicios**:
  - Ollama: Puerto 11434 (localhost only)
  - SRCS Application: Procesos Python
  - Base de datos SQLite: Archivo local
- **Red**: Conectado a red local del Smart Room

**Red Local**
- **Topolog√≠a**: Estrella con switch/router central
- **Protocolo**: Ethernet 1Gbps o WiFi 6
- **Segmentaci√≥n**: VLAN opcional para aislar tr√°fico IoT

**Dispositivos IoT**
- **Philips Hue**: Requiere bridge conectado a red
- **Nest Thermostat**: WiFi directo a router
- **C√°maras IP**: PoE o WiFi
- **Sonos**: WiFi directo

**Opcionales**
- **Web Browser**: Para interfaz de administraci√≥n (FastAPI)
- **Home Assistant**: Como intermediario para dispositivos heterog√©neos

---

## 6. Patrones Arquitect√≥nicos

### 6.1 Patr√≥n Agente Orquestador

**Descripci√≥n**: El LLM act√∫a como agente central que orquesta m√∫ltiples agentes especializados (servidores MCP).

**Ventajas**:
- Inteligencia centralizada con especializaci√≥n distribuida
- Facilita razonamiento de alto nivel
- Permite extensibilidad mediante nuevos agentes

**Implementaci√≥n**: LangGraph ReAct Agent con herramientas MCP

### 6.2 Patr√≥n Adapter (para Conectores IoT)

**Descripci√≥n**: Conectores traducen interfaz MCP est√°ndar a APIs espec√≠ficas de dispositivos.

**Ventajas**:
- Desacopla l√≥gica de negocio de detalles de dispositivos
- Facilita agregar nuevos dispositivos
- Centraliza manejo de errores espec√≠ficos de dispositivos

**Ejemplo**:
```python
class PhilipsHueAdapter:
    def turn_on(self, device_id, brightness, color):
        # Traduce a API de Philips Hue
        hue_command = self._translate_to_hue_format(brightness, color)
        self.hue_bridge.set_light(device_id, hue_command)
```

### 6.3 Patr√≥n Strategy (para Modelos LLM)

**Descripci√≥n**: Abstracci√≥n que permite intercambiar modelo LLM sin cambiar c√≥digo del agente.

**Ventajas**:
- Facilita experimentaci√≥n con diferentes modelos
- Permite selecci√≥n din√°mica seg√∫n recurso disponible
- Simplifica testing con modelos mock

**Implementaci√≥n**: LangChain AbstractLLM interface

### 6.4 Patr√≥n Observer (para Estado de Dispositivos)

**Descripci√≥n**: Dispositivos notifican cambios de estado al sistema.

**Ventajas**:
- Mantiene vista consistente del ambiente
- Permite reacciones autom√°ticas a eventos
- Reduce polling innecesario

**Implementaci√≥n**: Webhooks o MQTT subscriptions

### 6.5 Patr√≥n Command (para Acciones)

**Descripci√≥n**: Cada acci√≥n en dispositivo se encapsula como objeto Command.

**Ventajas**:
- Facilita deshacer/rehacer acciones
- Simplifica logging y auditor√≠a
- Permite composici√≥n de comandos

### 6.6 Patr√≥n Repository (para Datos)

**Descripci√≥n**: Abstracci√≥n de persistencia mediante repositorios.

**Ventajas**:
- Desacopla l√≥gica de negocio de DB
- Facilita testing con repositories mock
- Centraliza queries

**Implementaci√≥n**: SQLAlchemy con pattern Repository

---

## 7. Decisiones Arquitect√≥nicas (ADRs)

**NOTA IMPORTANTE**: Las decisiones arquitect√≥nicas fundamentales (ADR-001 a ADR-003) est√°n documentadas en [00-ADR-Base-Tecnologica.md](./00-ADR-Base-Tecnologica.md):
- **ADR-001**: Uso de mcp-client-cli como base del proyecto ‚≠ê **CR√çTICO**
- **ADR-002**: Stack tecnol√≥gico Python + LangChain
- **ADR-003**: SQLite como base de datos

Los siguientes ADRs son decisiones espec√≠ficas de dise√±o del sistema:

### ADR-004: Procesamiento Local vs. Cloud

**Contexto**: El sistema necesita procesar comandos de lenguaje natural y tomar decisiones.

**Decisi√≥n**: Ejecutar LLM localmente con Ollama + Llama, sin dependencia de servicios cloud.

**Razones**:
- Privacidad: Datos de usuario permanecen locales
- Latencia: Eliminaci√≥n de round-trip a internet
- Costo: Sin cargos por inferencia
- Autonom√≠a: Sistema funciona sin internet

**Consecuencias**:
- (+) Garant√≠a de privacidad
- (+) Latencia predecible y baja
- (-) Requiere hardware potente (GPU)
- (-) Limitado a modelos que caben en VRAM local

### ADR-005: Model Context Protocol como Capa de Comunicaci√≥n

**Contexto**: Necesidad de protocolo estandarizado para comunicaci√≥n entre LLM y agentes especializados.

**Decisi√≥n**: Adoptar MCP como protocolo oficial para comunicaci√≥n.

**Alternativas consideradas**:
- APIs REST personalizadas
- gRPC
- MQTT

**Razones**:
- Dise√±ado espec√≠ficamente para agentes AI
- Soporte nativo en LangChain
- Comunidad activa y especificaci√≥n abierta
- Facilita descubrimiento de capacidades

**Consecuencias**:
- (+) Interoperabilidad con ecosistema MCP
- (+) Protocolo bien documentado
- (+) Facilita extensibilidad
- (-) Protocolo relativamente nuevo (menos maduro que REST)

### ADR-006: LangGraph para Gesti√≥n de Estado del Agente

**Contexto**: El agente AI necesita mantener estado entre m√∫ltiples turnos de conversaci√≥n.

**Decisi√≥n**: Usar LangGraph con checkpoints en SQLite.

**Alternativas consideradas**:
- Estado en memoria (vol√°til)
- Redis para estado distribuido
- Custom state management

**Razones**:
- Integraci√≥n nativa con LangChain
- Soporte para grafos de estado complejos
- Persistencia autom√°tica con checkpoints
- Facilita debugging con visualizaci√≥n de grafo

**Consecuencias**:
- (+) Estado persistente entre reinicios
- (+) Facilita implementaci√≥n de ReAct pattern
- (+) Debugging simplificado
- (-) Overhead de persistencia en cada paso

**NOTA**: Los ADRs sobre selecci√≥n de base de datos (SQLite) y lenguaje de programaci√≥n (Python) han sido consolidados en [00-ADR-Base-Tecnologica.md](./00-ADR-Base-Tecnologica.md) como ADR-003 y ADR-002 respectivamente, donde se presentan en el contexto de la decisi√≥n de usar mcp-client-cli como base.

---

## 8. Flujo de Datos

### 8.1 Flujo de Comando de Voz Exitoso

```
1. Usuario: "Enciende las luces del sal√≥n al 70%"
   ‚îî‚îÄ> UI: Captura audio del micr√≥fono

2. UI: Conversi√≥n Speech-to-Text con Whisper
   ‚îî‚îÄ> Transcripci√≥n: "Enciende las luces del sal√≥n al 70%"

3. UI ‚Üí LLM Agent: Env√≠a texto transcrito
   ‚îî‚îÄ> NLP Processor: Analiza comando con Llama

4. NLP Processor ‚Üí LLM: Prompt de extracci√≥n de intenci√≥n
   ‚îî‚îÄ> LLM: Retorna Intent(action="turn_on", device="luces_sal√≥n", brightness=70)

5. Decision Engine: Valida intenci√≥n, consulta contexto
   ‚îî‚îÄ> Context Manager ‚Üí DB: ¬øExisten "luces_sal√≥n"? ‚Üí S√≠, device_id=hue_light_3

6. Action Planner: Crea plan de acci√≥n
   ‚îî‚îÄ> Plan: [Action(tool="lighting_turn_on", params={device_id:"hue_light_3", brightness:70})]

7. Action Planner ‚Üí MCP Coordinator: Solicita ejecuci√≥n
   ‚îî‚îÄ> MCP Coordinator ‚Üí MCP Lighting Server: Invoca lighting_turn_on(...)

8. MCP Lighting Server ‚Üí IoT Connector (Philips Hue): Delega ejecuci√≥n
   ‚îî‚îÄ> Philips Hue Adapter: Traduce a API Hue, env√≠a HTTP request

9. Philips Hue Bridge: Enciende bombilla al 70%
   ‚îî‚îÄ> Dispositivo f√≠sico: Luz enciende

10. Philips Hue Bridge ‚Üí Adapter: Responde success
    ‚îî‚îÄ> Adapter ‚Üí MCP Server: Retorna resultado estandarizado

11. MCP Server ‚Üí MCP Coordinator ‚Üí Action Planner: Confirma √©xito

12. Response Generator ‚Üí LLM: Solicita generaci√≥n de confirmaci√≥n
    ‚îî‚îÄ> LLM: "He encendido las luces del sal√≥n al 70%"

13. Response Generator ‚Üí UI: Env√≠a respuesta

14. UI: Text-to-Speech con Bark
    ‚îî‚îÄ> Audio: "He encendido las luces del sal√≥n al 70%"

15. Usuario: Escucha confirmaci√≥n
```

**Tiempo total**: ~1.8 segundos (dentro del objetivo de 2s)

### 8.2 Flujo de Comando Compuesto

```
Usuario: "Activa modo cine"

1-4. [Igual que flujo simple hasta extracci√≥n de intenci√≥n]

5. Decision Engine: Reconoce "modo cine" como escena predefinida
   ‚îî‚îÄ> Context Manager ‚Üí DB: Recupera Scene(name="modo_cine")
       Scene = {
         lights: {brightness:10, color:"warm_white"},
         climate: {temperature:21},
         entertainment: {device:"tv", source:"HDMI1", volume:60},
         blinds: {position:"closed"}
       }

6. Action Planner: Descompone en acciones paralelas
   ‚îî‚îÄ> Plan: [
         Action(tool="lighting_set_brightness", params={...}) [PARALLEL],
         Action(tool="lighting_set_color", params={...})      [PARALLEL],
         Action(tool="climate_set_temperature", params={...}) [PARALLEL],
         Action(tool="entertainment_power_on", params={...})  [SEQUENTIAL],
         Action(tool="entertainment_select_source", params={...}) [SEQUENTIAL],
       ]

7. MCP Coordinator: Ejecuta acciones paralelas simult√°neamente
   ‚îî‚îÄ> Invoca 3 servidores MCP en paralelo (lighting, climate)
       Espera confirmaci√≥n de todos
       Luego ejecuta acciones secuenciales de entertainment

8-15. [Ejecuci√≥n y confirmaci√≥n]

Respuesta: "He activado el modo cine: luces atenuadas al 10%, temperatura a 21 grados y TV encendida"
```

---

## Conclusi√≥n

Esta arquitectura proporciona:
- **Modularidad**: Componentes independientes y reemplazables
- **Extensibilidad**: F√°cil agregar nuevos servidores MCP y dispositivos
- **Privacidad**: Procesamiento completamente local
- **Escalabilidad**: Arquitectura preparada para crecimiento
- **Mantenibilidad**: C√≥digo organizado con separaci√≥n de responsabilidades

La adopci√≥n de MCP como protocolo central permite interoperabilidad futura con otros sistemas y facilita la investigaci√≥n en agentes AI colaborativos.

---

**Pr√≥ximos Pasos**: Ver documentos de Historias de Usuario (doc 02), Casos de Uso (doc 03) y Diagramas de Secuencia (doc 07) para detalles de implementaci√≥n.
